{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "oH3qKNRTWGHk"
      },
      "outputs": [],
      "source": [
        "# The Purpose is to build the NLP Model that can read the medical abstracts easier"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/Franck-Dernoncourt/pubmed-rct.git # Clone the Dataset from the git\n",
        "!ls pubmed-rct"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5FfI4NhGZcwY",
        "outputId": "d958bb60-37c0-46c1-f4a4-5bc0ff3fd9bf"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'pubmed-rct'...\n",
            "remote: Enumerating objects: 33, done.\u001b[K\n",
            "remote: Counting objects: 100% (8/8), done.\u001b[K\n",
            "remote: Compressing objects: 100% (3/3), done.\u001b[K\n",
            "remote: Total 33 (delta 5), reused 5 (delta 5), pack-reused 25\u001b[K\n",
            "Unpacking objects: 100% (33/33), 177.08 MiB | 5.98 MiB/s, done.\n",
            "PubMed_200k_RCT\n",
            "PubMed_200k_RCT_numbers_replaced_with_at_sign\n",
            "PubMed_20k_RCT\n",
            "PubMed_20k_RCT_numbers_replaced_with_at_sign\n",
            "README.md\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Download helper functions\n",
        "!wget https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/extras/helper_functions.py\n",
        "from helper_functions import calculate_results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zeC-jU0Eo4l4",
        "outputId": "2bc70875-140b-4893-b7e9-2acece26fb39"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-05-01 04:38:48--  https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/extras/helper_functions.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 10246 (10K) [text/plain]\n",
            "Saving to: ‘helper_functions.py’\n",
            "\n",
            "helper_functions.py 100%[===================>]  10.01K  --.-KB/s    in 0s      \n",
            "\n",
            "2023-05-01 04:38:48 (84.5 MB/s) - ‘helper_functions.py’ saved [10246/10246]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Looking what files are there in pubmet 20k\n",
        "!ls pubmed-rct/PubMed_20k_RCT_numbers_replaced_with_at_sign\n",
        "# Check what files are in the PubMed_20K dataset \n",
        "!ls pubmed-rct/PubMed_20k_RCT"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W0Wk9U6caEHL",
        "outputId": "65542051-8992-4d32-8461-aed90dec9f56"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dev.txt  test.txt  train.txt\n",
            "dev.txt  test.txt  train.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_directory='/content/pubmed-rct/PubMed_20k_RCT_numbers_replaced_with_at_sign/'#Data Directory"
      ],
      "metadata": {
        "id": "1ulV9kAYgQlC"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os"
      ],
      "metadata": {
        "id": "WQkNEox2gQPH"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "filenames=[data_directory+filename for filename in os.listdir(data_directory)]"
      ],
      "metadata": {
        "id": "i2oaNPkHge1K"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "filenames#Getting the files Train data,Validation data,Test data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bhtDRiPngxlO",
        "outputId": "6c7f099b-98d0-4351-e7b2-f87bb8f41c2a"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['/content/pubmed-rct/PubMed_20k_RCT_numbers_replaced_with_at_sign/test.txt',\n",
              " '/content/pubmed-rct/PubMed_20k_RCT_numbers_replaced_with_at_sign/dev.txt',\n",
              " '/content/pubmed-rct/PubMed_20k_RCT_numbers_replaced_with_at_sign/train.txt']"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Processing the data"
      ],
      "metadata": {
        "id": "LOpMfyJBg6aj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Knowing the train dataset"
      ],
      "metadata": {
        "id": "UYktQr87qO90"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_lines(filepath):#Reading the data in the path\n",
        "  with open(filepath,'r') as f:\n",
        "     return f.readlines()\n"
      ],
      "metadata": {
        "id": "HPAqJlLctmXW"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_lines=get_lines(data_directory+'train.txt')"
      ],
      "metadata": {
        "id": "EPtIG9DruL2a"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_lines[:100] #Knowing about the abstarcts in the file"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HDCI2V9eudnl",
        "outputId": "a1839df2-2505-4953-b065-2a7f1b8d449b"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['###24293578\\n',\n",
              " 'OBJECTIVE\\tTo investigate the efficacy of @ weeks of daily low-dose oral prednisolone in improving pain , mobility , and systemic low-grade inflammation in the short term and whether the effect would be sustained at @ weeks in older adults with moderate to severe knee osteoarthritis ( OA ) .\\n',\n",
              " 'METHODS\\tA total of @ patients with primary knee OA were randomized @:@ ; @ received @ mg/day of prednisolone and @ received placebo for @ weeks .\\n',\n",
              " 'METHODS\\tOutcome measures included pain reduction and improvement in function scores and systemic inflammation markers .\\n',\n",
              " 'METHODS\\tPain was assessed using the visual analog pain scale ( @-@ mm ) .\\n',\n",
              " 'METHODS\\tSecondary outcome measures included the Western Ontario and McMaster Universities Osteoarthritis Index scores , patient global assessment ( PGA ) of the severity of knee OA , and @-min walk distance ( @MWD ) .\\n',\n",
              " 'METHODS\\tSerum levels of interleukin @ ( IL-@ ) , IL-@ , tumor necrosis factor ( TNF ) - , and high-sensitivity C-reactive protein ( hsCRP ) were measured .\\n',\n",
              " 'RESULTS\\tThere was a clinically relevant reduction in the intervention group compared to the placebo group for knee pain , physical function , PGA , and @MWD at @ weeks .\\n',\n",
              " 'RESULTS\\tThe mean difference between treatment arms ( @ % CI ) was @ ( @-@ @ ) , p < @ ; @ ( @-@ @ ) , p < @ ; @ ( @-@ @ ) , p < @ ; and @ ( @-@ @ ) , p < @ , respectively .\\n',\n",
              " 'RESULTS\\tFurther , there was a clinically relevant reduction in the serum levels of IL-@ , IL-@ , TNF - , and hsCRP at @ weeks in the intervention group when compared to the placebo group .\\n',\n",
              " 'RESULTS\\tThese differences remained significant at @ weeks .\\n',\n",
              " 'RESULTS\\tThe Outcome Measures in Rheumatology Clinical Trials-Osteoarthritis Research Society International responder rate was @ % in the intervention group and @ % in the placebo group ( p < @ ) .\\n',\n",
              " 'CONCLUSIONS\\tLow-dose oral prednisolone had both a short-term and a longer sustained effect resulting in less knee pain , better physical function , and attenuation of systemic inflammation in older patients with knee OA ( ClinicalTrials.gov identifier NCT@ ) .\\n',\n",
              " '\\n',\n",
              " '###24854809\\n',\n",
              " 'BACKGROUND\\tEmotional eating is associated with overeating and the development of obesity .\\n',\n",
              " 'BACKGROUND\\tYet , empirical evidence for individual ( trait ) differences in emotional eating and cognitive mechanisms that contribute to eating during sad mood remain equivocal .\\n',\n",
              " 'OBJECTIVE\\tThe aim of this study was to test if attention bias for food moderates the effect of self-reported emotional eating during sad mood ( vs neutral mood ) on actual food intake .\\n',\n",
              " 'OBJECTIVE\\tIt was expected that emotional eating is predictive of elevated attention for food and higher food intake after an experimentally induced sad mood and that attentional maintenance on food predicts food intake during a sad versus a neutral mood .\\n',\n",
              " 'METHODS\\tParticipants ( N = @ ) were randomly assigned to one of the two experimental mood induction conditions ( sad/neutral ) .\\n',\n",
              " 'METHODS\\tAttentional biases for high caloric foods were measured by eye tracking during a visual probe task with pictorial food and neutral stimuli .\\n',\n",
              " 'METHODS\\tSelf-reported emotional eating was assessed with the Dutch Eating Behavior Questionnaire ( DEBQ ) and ad libitum food intake was tested by a disguised food offer .\\n',\n",
              " 'RESULTS\\tHierarchical multivariate regression modeling showed that self-reported emotional eating did not account for changes in attention allocation for food or food intake in either condition .\\n',\n",
              " 'RESULTS\\tYet , attention maintenance on food cues was significantly related to increased intake specifically in the neutral condition , but not in the sad mood condition .\\n',\n",
              " 'CONCLUSIONS\\tThe current findings show that self-reported emotional eating ( based on the DEBQ ) might not validly predict who overeats when sad , at least not in a laboratory setting with healthy women .\\n',\n",
              " 'CONCLUSIONS\\tResults further suggest that attention maintenance on food relates to eating motivation when in a neutral affective state , and might therefore be a cognitive mechanism contributing to increased food intake in general , but maybe not during sad mood .\\n',\n",
              " '\\n',\n",
              " '###25165090\\n',\n",
              " 'BACKGROUND\\tAlthough working smoke alarms halve deaths in residential fires , many households do not keep alarms operational .\\n',\n",
              " 'BACKGROUND\\tWe tested whether theory-based education increases alarm operability .\\n',\n",
              " 'METHODS\\tRandomised multiarm trial , with a single arm randomly selected for use each day , in low-income neighbourhoods in Maryland , USA .\\n',\n",
              " \"METHODS\\tIntervention arms : ( @ ) Full Education combining a health belief module with a social-cognitive theory module that provided hands-on practice installing alarm batteries and using the alarm 's hush button ; ( @ ) Hands-on Practice social-cognitive module supplemented by typical fire department education ; ( @ ) Current Norm receiving typical fire department education only .\\n\",\n",
              " 'METHODS\\tFour hundred and thirty-six homes recruited through churches or by knocking on doors in @-@ .\\n',\n",
              " 'METHODS\\tFollow-up visits checked alarm operability in @ homes ( @ % ) @-@ @ years after installation .\\n',\n",
              " 'METHODS\\tnumber of homes with working alarms defined as alarms with working batteries or hard-wired and number of working alarms per home .\\n',\n",
              " 'METHODS\\tRegressions controlled for alarm status preintervention ; demographics and beliefs about fire risks and alarm effectiveness .\\n',\n",
              " 'RESULTS\\tHomes in the Full Education and Practice arms were more likely to have a functioning smoke alarm at follow-up ( OR = @ , @ % CI @ to @ ) and had an average of @ more working alarms per home ( @ % CI @ to @ ) .\\n',\n",
              " 'RESULTS\\tWorking alarms per home rose @ % .\\n',\n",
              " 'RESULTS\\tFull Education and Practice had similar effectiveness ( p = @ on both outcome measures ) .\\n',\n",
              " 'CONCLUSIONS\\tWithout exceeding typical fire department installation time , installers can achieve greater smoke alarm operability .\\n',\n",
              " 'CONCLUSIONS\\tHands-on practice is key .\\n',\n",
              " 'CONCLUSIONS\\tTwo years after installation , for every three homes that received hands-on practice , one had an additional working alarm .\\n',\n",
              " 'BACKGROUND\\thttp://www.clinicaltrials.gov number NCT@ .\\n',\n",
              " '\\n',\n",
              " '###24633056\\n',\n",
              " 'OBJECTIVE\\tTo evaluate the performance ( efficacy , safety and acceptability ) of a new micro-adherent absorbent dressing ( UrgoClean ) compared with a hydrofiber dressing ( Aquacel ) in the local management of venous leg ulcers , in the debridement stage .\\n',\n",
              " 'METHODS\\tA non-inferiority European randomised controlled clinical trial ( RCT ) was conducted in @ centres , on patients presenting with venous or predominantly venous , mixed aetiology leg ulcers at their sloughy stage ( with more than @ % of the wound bed covered with slough at baseline ) .\\n',\n",
              " 'METHODS\\tPatients were followed over a @-week period and assessed weekly .\\n',\n",
              " 'METHODS\\tThe primary judgement criteria was the relative regression of the wound surface area after the @-week treatment period .\\n',\n",
              " 'METHODS\\tSecondary endpoints were the relative reduction of sloughy tissue and the percentage of patients presenting with a debrided wound .\\n',\n",
              " 'RESULTS\\tAltogether , @ patients were randomised to either UrgoClean ( test group ; n = @ ) or Aquacel ( control group ; n = @ ) dressings .\\n',\n",
              " 'RESULTS\\tRegarding the wound healing process predictive factors ( wound area , duration , ABPI value , recurrence ) , at baseline , the two groups were well balanced , for both wound and patient characteristics .\\n',\n",
              " 'RESULTS\\tCompression therapy was administered to both groups and after a median @-day treatment period , the percentage of relative reduction of the wound surface area was very similar ( -@ % vs -@ % in the UrgoClean and control groups , respectively ) .\\n',\n",
              " 'RESULTS\\tWhen considering the secondary criteria at week @ , the relative reduction of sloughy tissue was significantly higher in the UrgoClean group than in the control group ( -@ % vs -@,@ % ; p = @ ) .\\n',\n",
              " 'RESULTS\\tThe percentage of debrided wounds was also significantly higher in the test group ( @ % vs @ % ; p = @ ) .\\n',\n",
              " \"CONCLUSIONS\\tThis ` EARTH ' RCT confirmed that the UrgoClean dressing has similar efficacy and safety compared to Aquacel .\\n\",\n",
              " 'CONCLUSIONS\\tHowever , UrgoClean also showed better autolytic properties than the control group in the management of venous leg ulcers at the sloughy stage .\\n',\n",
              " 'CONCLUSIONS\\tThe new UrgoClean dressing therefore represents a promising therapeutic option within the current range of autolytic dressings available .\\n',\n",
              " 'BACKGROUND\\tThis study was sponsored by a grant from the pharmaceutical company Laboratoires Urgo .\\n',\n",
              " 'BACKGROUND\\tS. Bohbot and O. Tacca are employees of Laboratoires Urgo .\\n',\n",
              " 'BACKGROUND\\tS. Meaume , J. Dissemond and G. Perceau have received monetary compensation as presenters for Laboratoires Urgo .\\n',\n",
              " 'BACKGROUND\\tData management and statistical analyses were conducted independently by Vertical ( Paris , France ) .\\n',\n",
              " '\\n',\n",
              " '###24814304\\n',\n",
              " 'OBJECTIVE\\tEye movements ( EM ) during recall of an aversive memory is a treatment element unique to Eye Movement Desensitization and Reprocessing ( EMDR ) .\\n',\n",
              " 'OBJECTIVE\\tExperimental studies have shown that EM reduce memory vividness and/or emotionality shortly after the intervention .\\n',\n",
              " 'OBJECTIVE\\tHowever , it is unclear whether the immediate effects of the intervention reflect actual changes in memory .\\n',\n",
              " 'OBJECTIVE\\tThe aim of this study was to test whether immediate reductions in memory vividness and emotionality persist at a @h follow up and whether the magnitude of these effects is related to the duration of the intervention .\\n',\n",
              " \"METHODS\\tSeventy-three undergraduates recalled two negative autobiographical memories , one with EM ( `` recall with EM '' ) and one without ( `` recall only '' ) .\\n\",\n",
              " 'METHODS\\tHalf of participants recalled each memory for four periods of @s , the other half for eight periods of @s .\\n',\n",
              " 'METHODS\\tMemory vividness/emotionality were self-rated at a pre-test , an immediate post-test , and a @h follow-up test .\\n',\n",
              " 'RESULTS\\tIn both duration groups , recall with EM , but not recall only , caused an immediate decrease in memory vividness .\\n',\n",
              " 'RESULTS\\tThere were no immediate reductions in memory emotionality .\\n',\n",
              " \"RESULTS\\tFurthermore , only the ` eight periods ' group showed that recall with EM , but not recall only , caused a decrease in both memory emotionality and memory vividness from the pre-test to the follow-up .\\n\",\n",
              " 'CONCLUSIONS\\tOnly self-report measures were used .\\n',\n",
              " 'CONCLUSIONS\\tThe findings suggest that recall with EM causes @-hchanges in memory vividness/emotionality , which may explain part of the EMDR treatment effect , and these effects are related to intervention duration .\\n',\n",
              " '\\n',\n",
              " '###25825539\\n',\n",
              " 'OBJECTIVE\\tFew studies have tested the impact of motivational interviewing ( MI ) delivered by primary care providers on pediatric obesity .\\n',\n",
              " 'OBJECTIVE\\tThis study tested the efficacy of MI delivered by providers and registered dietitians ( RDs ) to parents of overweight children aged @ through @ .\\n',\n",
              " 'METHODS\\tForty-two practices from the Pediatric Research in Office Settings Network of the American Academy of Pediatrics were randomly assigned to @ of @ groups .\\n',\n",
              " 'METHODS\\tGroup @ ( usual care ) measured BMI percentile at baseline and @ - and @-year follow-up .\\n',\n",
              " 'METHODS\\tGroup @ ( provider only ) delivered @ MI counseling sessions to parents of the index child over @ years .\\n',\n",
              " 'METHODS\\tGroup @ ( provider + RD ) delivered @ provider MI sessions plus @ MI sessions from a RD. .\\n',\n",
              " 'METHODS\\tThe primary outcome was child BMI percentile at @-year follow up .\\n',\n",
              " 'RESULTS\\tAt @-year follow-up , the adjusted BMI percentile was @ , @ , and @ for groups @ , @ , and @ , respectively .\\n',\n",
              " 'RESULTS\\tThe group @ mean was significantly ( P = @ ) lower than group @ .\\n',\n",
              " 'RESULTS\\tMean changes from baseline in BMI percentile were @ , @ , and @ across groups @ , @ , and @ .\\n',\n",
              " 'CONCLUSIONS\\tMI delivered by providers and RDs ( group @ ) resulted in statistically significant reductions in BMI percentile .\\n',\n",
              " 'CONCLUSIONS\\tResearch is needed to determine the clinical significance and persistence of the BMI effects observed .\\n',\n",
              " 'CONCLUSIONS\\tHow the intervention can be brought to scale ( in particular , how to train physicians to use MI effectively and how best to train RDs and integrate them into primary care settings ) also merits future research .\\n',\n",
              " '\\n',\n",
              " '###24507941\\n',\n",
              " 'BACKGROUND\\tAntithrombin ( AT ) concentrations are reduced after cardiac surgery with cardiopulmonary bypass compared with the preoperative levels .\\n',\n",
              " 'BACKGROUND\\tLow postoperative AT is associated with worse short - and mid-term clinical outcomes .\\n',\n",
              " 'BACKGROUND\\tThe aim of the study is to evaluate the effects of AT administration on activation of the coagulation and fibrinolytic systems , platelet function , and the inflammatory response in patients with low postoperative AT levels .\\n',\n",
              " 'METHODS\\tSixty patients with postoperative AT levels of less than @ % were randomly assigned to receive purified AT ( @ IU in three administrations ) or placebo in the postoperative intensive care unit .\\n',\n",
              " 'METHODS\\tThirty patients with postoperative AT levels greater than @ % were observed as controls .\\n',\n",
              " 'METHODS\\tInterleukin @ ( a marker of inflammation ) , prothrombin fragment @-@ ( a marker of thrombin generation ) , plasmin-antiplasmin complex ( a marker of fibrinolysis ) , and platelet factor @ ( a marker of platelet activation ) were measured at six different times .\\n',\n",
              " 'RESULTS\\tCompared with the no AT group and control patients , patients receiving AT showed significantly higher AT values until @ hours after the last administration .\\n']"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_text_with_line_numbers(filename):\n",
        "  input_lines = get_lines(filename) # get all lines from filename\n",
        "  abstract_lines = \"\" # create an empty abstract\n",
        "  abstract_samples = [] # create an empty list of abstracts\n",
        "  \n",
        "  # Loop through each line in target file\n",
        "  for line in input_lines:\n",
        "    if line.startswith(\"###\"): # check to see if line is an ID line\n",
        "      abstract_id = line\n",
        "      abstract_lines = \"\" # reset abstract string\n",
        "    elif line.isspace(): # check to see if line is a new line\n",
        "      abstract_line_split = abstract_lines.splitlines() # split abstract into separate lines\n",
        "\n",
        "      # Iterate through each line in abstract and count them at the same time\n",
        "      for abstract_line_number, abstract_line in enumerate(abstract_line_split):\n",
        "        line_data = {} # create empty dict to store data from line\n",
        "        target_text_split = abstract_line.split(\"\\t\") # split target label from text\n",
        "        line_data[\"target\"] = target_text_split[0] # get target label\n",
        "        line_data[\"text\"] = target_text_split[1].lower() # get target text and lower it\n",
        "        line_data[\"line_number\"] = abstract_line_number # what number line does the line appear in the abstract?\n",
        "        line_data[\"total_lines\"] = len(abstract_line_split) - 1 # how many total lines are in the abstract? (start from 0)\n",
        "        abstract_samples.append(line_data) # add line data to abstract samples list\n",
        "    \n",
        "    else: # if the above conditions aren't fulfilled, the line contains a labelled sentence\n",
        "      abstract_lines += line\n",
        "  \n",
        "  return abstract_samples"
      ],
      "metadata": {
        "id": "xP86VnHe-42b"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get data from file and preprocess it Train data,validation data and the test data\n",
        "%%time\n",
        "train_samples = preprocess_text_with_line_numbers(data_directory + \"train.txt\")\n",
        "val_samples = preprocess_text_with_line_numbers(data_directory + \"dev.txt\") # dev is another name for validation set\n",
        "test_samples = preprocess_text_with_line_numbers(data_directory + \"test.txt\")\n",
        "len(train_samples), len(val_samples), len(test_samples)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QahD9IdV-9pg",
        "outputId": "902d9e53-3d8f-42e5-b5dd-68a64fceb4aa"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 352 ms, sys: 69.3 ms, total: 422 ms\n",
            "Wall time: 424 ms\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(180040, 30212, 30135)"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_samples[:20] #Train Samples"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S7CoTlZLCfXY",
        "outputId": "310ce680-dc0f-4477-b09a-22703985f022"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'target': 'OBJECTIVE',\n",
              "  'text': 'to investigate the efficacy of @ weeks of daily low-dose oral prednisolone in improving pain , mobility , and systemic low-grade inflammation in the short term and whether the effect would be sustained at @ weeks in older adults with moderate to severe knee osteoarthritis ( oa ) .',\n",
              "  'line_number': 0,\n",
              "  'total_lines': 11},\n",
              " {'target': 'METHODS',\n",
              "  'text': 'a total of @ patients with primary knee oa were randomized @:@ ; @ received @ mg/day of prednisolone and @ received placebo for @ weeks .',\n",
              "  'line_number': 1,\n",
              "  'total_lines': 11},\n",
              " {'target': 'METHODS',\n",
              "  'text': 'outcome measures included pain reduction and improvement in function scores and systemic inflammation markers .',\n",
              "  'line_number': 2,\n",
              "  'total_lines': 11},\n",
              " {'target': 'METHODS',\n",
              "  'text': 'pain was assessed using the visual analog pain scale ( @-@ mm ) .',\n",
              "  'line_number': 3,\n",
              "  'total_lines': 11},\n",
              " {'target': 'METHODS',\n",
              "  'text': 'secondary outcome measures included the western ontario and mcmaster universities osteoarthritis index scores , patient global assessment ( pga ) of the severity of knee oa , and @-min walk distance ( @mwd ) .',\n",
              "  'line_number': 4,\n",
              "  'total_lines': 11},\n",
              " {'target': 'METHODS',\n",
              "  'text': 'serum levels of interleukin @ ( il-@ ) , il-@ , tumor necrosis factor ( tnf ) - , and high-sensitivity c-reactive protein ( hscrp ) were measured .',\n",
              "  'line_number': 5,\n",
              "  'total_lines': 11},\n",
              " {'target': 'RESULTS',\n",
              "  'text': 'there was a clinically relevant reduction in the intervention group compared to the placebo group for knee pain , physical function , pga , and @mwd at @ weeks .',\n",
              "  'line_number': 6,\n",
              "  'total_lines': 11},\n",
              " {'target': 'RESULTS',\n",
              "  'text': 'the mean difference between treatment arms ( @ % ci ) was @ ( @-@ @ ) , p < @ ; @ ( @-@ @ ) , p < @ ; @ ( @-@ @ ) , p < @ ; and @ ( @-@ @ ) , p < @ , respectively .',\n",
              "  'line_number': 7,\n",
              "  'total_lines': 11},\n",
              " {'target': 'RESULTS',\n",
              "  'text': 'further , there was a clinically relevant reduction in the serum levels of il-@ , il-@ , tnf - , and hscrp at @ weeks in the intervention group when compared to the placebo group .',\n",
              "  'line_number': 8,\n",
              "  'total_lines': 11},\n",
              " {'target': 'RESULTS',\n",
              "  'text': 'these differences remained significant at @ weeks .',\n",
              "  'line_number': 9,\n",
              "  'total_lines': 11},\n",
              " {'target': 'RESULTS',\n",
              "  'text': 'the outcome measures in rheumatology clinical trials-osteoarthritis research society international responder rate was @ % in the intervention group and @ % in the placebo group ( p < @ ) .',\n",
              "  'line_number': 10,\n",
              "  'total_lines': 11},\n",
              " {'target': 'CONCLUSIONS',\n",
              "  'text': 'low-dose oral prednisolone had both a short-term and a longer sustained effect resulting in less knee pain , better physical function , and attenuation of systemic inflammation in older patients with knee oa ( clinicaltrials.gov identifier nct@ ) .',\n",
              "  'line_number': 11,\n",
              "  'total_lines': 11},\n",
              " {'target': 'BACKGROUND',\n",
              "  'text': 'emotional eating is associated with overeating and the development of obesity .',\n",
              "  'line_number': 0,\n",
              "  'total_lines': 10},\n",
              " {'target': 'BACKGROUND',\n",
              "  'text': 'yet , empirical evidence for individual ( trait ) differences in emotional eating and cognitive mechanisms that contribute to eating during sad mood remain equivocal .',\n",
              "  'line_number': 1,\n",
              "  'total_lines': 10},\n",
              " {'target': 'OBJECTIVE',\n",
              "  'text': 'the aim of this study was to test if attention bias for food moderates the effect of self-reported emotional eating during sad mood ( vs neutral mood ) on actual food intake .',\n",
              "  'line_number': 2,\n",
              "  'total_lines': 10},\n",
              " {'target': 'OBJECTIVE',\n",
              "  'text': 'it was expected that emotional eating is predictive of elevated attention for food and higher food intake after an experimentally induced sad mood and that attentional maintenance on food predicts food intake during a sad versus a neutral mood .',\n",
              "  'line_number': 3,\n",
              "  'total_lines': 10},\n",
              " {'target': 'METHODS',\n",
              "  'text': 'participants ( n = @ ) were randomly assigned to one of the two experimental mood induction conditions ( sad/neutral ) .',\n",
              "  'line_number': 4,\n",
              "  'total_lines': 10},\n",
              " {'target': 'METHODS',\n",
              "  'text': 'attentional biases for high caloric foods were measured by eye tracking during a visual probe task with pictorial food and neutral stimuli .',\n",
              "  'line_number': 5,\n",
              "  'total_lines': 10},\n",
              " {'target': 'METHODS',\n",
              "  'text': 'self-reported emotional eating was assessed with the dutch eating behavior questionnaire ( debq ) and ad libitum food intake was tested by a disguised food offer .',\n",
              "  'line_number': 6,\n",
              "  'total_lines': 10},\n",
              " {'target': 'RESULTS',\n",
              "  'text': 'hierarchical multivariate regression modeling showed that self-reported emotional eating did not account for changes in attention allocation for food or food intake in either condition .',\n",
              "  'line_number': 7,\n",
              "  'total_lines': 10}]"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd #Visualize the Dictionary and converting to Data Frame and visualizing that\n",
        "train_df = pd.DataFrame(train_samples)\n",
        "val_df = pd.DataFrame(val_samples)\n",
        "test_df = pd.DataFrame(test_samples)\n",
        "train_df.head(14)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 488
        },
        "id": "4Twx8ISIOkPA",
        "outputId": "58a4e64f-9cd9-49be-f977-2035bb57ef17"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         target                                               text  \\\n",
              "0     OBJECTIVE  to investigate the efficacy of @ weeks of dail...   \n",
              "1       METHODS  a total of @ patients with primary knee oa wer...   \n",
              "2       METHODS  outcome measures included pain reduction and i...   \n",
              "3       METHODS  pain was assessed using the visual analog pain...   \n",
              "4       METHODS  secondary outcome measures included the wester...   \n",
              "5       METHODS  serum levels of interleukin @ ( il-@ ) , il-@ ...   \n",
              "6       RESULTS  there was a clinically relevant reduction in t...   \n",
              "7       RESULTS  the mean difference between treatment arms ( @...   \n",
              "8       RESULTS  further , there was a clinically relevant redu...   \n",
              "9       RESULTS  these differences remained significant at @ we...   \n",
              "10      RESULTS  the outcome measures in rheumatology clinical ...   \n",
              "11  CONCLUSIONS  low-dose oral prednisolone had both a short-te...   \n",
              "12   BACKGROUND  emotional eating is associated with overeating...   \n",
              "13   BACKGROUND  yet , empirical evidence for individual ( trai...   \n",
              "\n",
              "    line_number  total_lines  \n",
              "0             0           11  \n",
              "1             1           11  \n",
              "2             2           11  \n",
              "3             3           11  \n",
              "4             4           11  \n",
              "5             5           11  \n",
              "6             6           11  \n",
              "7             7           11  \n",
              "8             8           11  \n",
              "9             9           11  \n",
              "10           10           11  \n",
              "11           11           11  \n",
              "12            0           10  \n",
              "13            1           10  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ea63a18d-7746-4416-96bf-bd040eac26a1\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>target</th>\n",
              "      <th>text</th>\n",
              "      <th>line_number</th>\n",
              "      <th>total_lines</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>OBJECTIVE</td>\n",
              "      <td>to investigate the efficacy of @ weeks of dail...</td>\n",
              "      <td>0</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>METHODS</td>\n",
              "      <td>a total of @ patients with primary knee oa wer...</td>\n",
              "      <td>1</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>METHODS</td>\n",
              "      <td>outcome measures included pain reduction and i...</td>\n",
              "      <td>2</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>METHODS</td>\n",
              "      <td>pain was assessed using the visual analog pain...</td>\n",
              "      <td>3</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>METHODS</td>\n",
              "      <td>secondary outcome measures included the wester...</td>\n",
              "      <td>4</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>METHODS</td>\n",
              "      <td>serum levels of interleukin @ ( il-@ ) , il-@ ...</td>\n",
              "      <td>5</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>RESULTS</td>\n",
              "      <td>there was a clinically relevant reduction in t...</td>\n",
              "      <td>6</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>RESULTS</td>\n",
              "      <td>the mean difference between treatment arms ( @...</td>\n",
              "      <td>7</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>RESULTS</td>\n",
              "      <td>further , there was a clinically relevant redu...</td>\n",
              "      <td>8</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>RESULTS</td>\n",
              "      <td>these differences remained significant at @ we...</td>\n",
              "      <td>9</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>RESULTS</td>\n",
              "      <td>the outcome measures in rheumatology clinical ...</td>\n",
              "      <td>10</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>CONCLUSIONS</td>\n",
              "      <td>low-dose oral prednisolone had both a short-te...</td>\n",
              "      <td>11</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>BACKGROUND</td>\n",
              "      <td>emotional eating is associated with overeating...</td>\n",
              "      <td>0</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>BACKGROUND</td>\n",
              "      <td>yet , empirical evidence for individual ( trai...</td>\n",
              "      <td>1</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ea63a18d-7746-4416-96bf-bd040eac26a1')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-ea63a18d-7746-4416-96bf-bd040eac26a1 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-ea63a18d-7746-4416-96bf-bd040eac26a1');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_df.total_lines.plot.hist();"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 431
        },
        "id": "VPex7bonOmF8",
        "outputId": "3300b521-6b91-4355-c3d6-cb2c5e626625"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract labels (\"target\" columns) and encode them into integers \n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "label_encoder = LabelEncoder()\n",
        "train_labels_encoded = label_encoder.fit_transform(train_df[\"target\"].to_numpy())\n",
        "val_labels_encoded = label_encoder.transform(val_df[\"target\"].to_numpy())\n",
        "test_labels_encoded = label_encoder.transform(test_df[\"target\"].to_numpy())\n",
        "\n",
        "# Check what training labels look like\n",
        "train_labels_encoded"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DBSnwtnBRBuZ",
        "outputId": "84dc297c-de7e-456b-b9c2-a37b5db088d7"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([3, 2, 2, ..., 4, 1, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_labels_encoded"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MrFok_-ztEtE",
        "outputId": "e34218d2-9c86-4cfd-c4d9-273bff32d395"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([3, 2, 2, ..., 4, 1, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get class names and number of classes from LabelEncoder instance \n",
        "num_classes = len(label_encoder.classes_)\n",
        "class_names = label_encoder.classes_\n",
        "num_classes, class_names"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "40_-OIUuc_Y7",
        "outputId": "394fdc51-e8ea-49e0-f207-1e3ff6e10d3a"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5,\n",
              " array(['BACKGROUND', 'CONCLUSIONS', 'METHODS', 'OBJECTIVE', 'RESULTS'],\n",
              "       dtype=object))"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert abstract text lines into lists \n",
        "train_sentences = train_df[\"text\"].tolist()\n",
        "val_sentences = val_df[\"text\"].tolist()\n",
        "test_sentences = test_df[\"text\"].tolist()\n",
        "len(train_sentences), len(val_sentences), len(test_sentences)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q9PiWNtmdLok",
        "outputId": "dee86419-3f3f-42dd-b3ba-7d7fe68f63d4"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(180040, 30212, 30135)"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#BaseLine Model"
      ],
      "metadata": {
        "id": "ivrYut1rVIkk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer#Importing the TfidfVectorizer,Decision tree\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "# Create a pipeline\n",
        "model_0 = Pipeline([\n",
        "  (\"tf-idf\", TfidfVectorizer()),\n",
        "  (\"clf\",  DecisionTreeClassifier(max_depth=50))\n",
        "])\n",
        "\n",
        "# Fit the pipeline to the training data\n",
        "model_0.fit(X=train_sentences, \n",
        "            y=train_labels_encoded);"
      ],
      "metadata": {
        "id": "dEFUHcXudCWi"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_0.score(X=val_sentences,\n",
        "              y=val_labels_encoded)#Evaluate on Validation data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2gh1b-KgeyPv",
        "outputId": "daeac8c1-eb50-4312-d396-18ad988ef6dd"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6967761154508142"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_pred=model_0.predict(test_sentences)#Testing on test data"
      ],
      "metadata": {
        "id": "YJ37s1QRe0G5"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Testing Baseline Model results"
      ],
      "metadata": {
        "id": "4DMOHpAeZPsS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "calculate_results(test_labels_encoded,test_pred)#Getting the accuarcy ,precision ,recall and F1 "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MHG4WWxxhaXt",
        "outputId": "4f970148-2143-4fb2-d06e-eac204664116"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 68.9795918367347,\n",
              " 'precision': 0.6840100239710493,\n",
              " 'recall': 0.689795918367347,\n",
              " 'f1': 0.685174244190681}"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "val_labels_encoded"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MXF8QKdYgQUu",
        "outputId": "99db9056-ed60-41cc-abe5-94ead67b8dc4"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 3, ..., 4, 1, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Preparing the model for the neural networks"
      ],
      "metadata": {
        "id": "6BPDOlizrMqg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf #Importing Required Libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tensorflow.keras import layers"
      ],
      "metadata": {
        "id": "kyV7M-HRrU6t"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_sentences[:10]#Going Through at the train sentences"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y_oRRQUS0-1N",
        "outputId": "b9480d2f-a493-4ba8-e1c1-be15034c452b"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['to investigate the efficacy of @ weeks of daily low-dose oral prednisolone in improving pain , mobility , and systemic low-grade inflammation in the short term and whether the effect would be sustained at @ weeks in older adults with moderate to severe knee osteoarthritis ( oa ) .',\n",
              " 'a total of @ patients with primary knee oa were randomized @:@ ; @ received @ mg/day of prednisolone and @ received placebo for @ weeks .',\n",
              " 'outcome measures included pain reduction and improvement in function scores and systemic inflammation markers .',\n",
              " 'pain was assessed using the visual analog pain scale ( @-@ mm ) .',\n",
              " 'secondary outcome measures included the western ontario and mcmaster universities osteoarthritis index scores , patient global assessment ( pga ) of the severity of knee oa , and @-min walk distance ( @mwd ) .',\n",
              " 'serum levels of interleukin @ ( il-@ ) , il-@ , tumor necrosis factor ( tnf ) - , and high-sensitivity c-reactive protein ( hscrp ) were measured .',\n",
              " 'there was a clinically relevant reduction in the intervention group compared to the placebo group for knee pain , physical function , pga , and @mwd at @ weeks .',\n",
              " 'the mean difference between treatment arms ( @ % ci ) was @ ( @-@ @ ) , p < @ ; @ ( @-@ @ ) , p < @ ; @ ( @-@ @ ) , p < @ ; and @ ( @-@ @ ) , p < @ , respectively .',\n",
              " 'further , there was a clinically relevant reduction in the serum levels of il-@ , il-@ , tnf - , and hscrp at @ weeks in the intervention group when compared to the placebo group .',\n",
              " 'these differences remained significant at @ weeks .']"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sen_lens=[len(sentence.split()) for sentence in train_sentences]#Knowing about the average sentence Length\n",
        "avg_sen_len=np.mean(sen_lens)\n",
        "avg_sen_len"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zTRYf29I5qAq",
        "outputId": "86120f69-3b01-4153-edf0-b58e17a458c3"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "26.338269273494777"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt#Plot no of tokens in each sentence\n",
        "plt.hist(sen_lens,bins=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 519
        },
        "id": "eAybaFme1np7",
        "outputId": "48d7fde1-de8f-43dc-bd9b-c7a48bc8234b"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([1.25846e+05, 4.78220e+04, 5.37600e+03, 7.86000e+02, 1.46000e+02,\n",
              "        3.20000e+01, 1.90000e+01, 8.00000e+00, 3.00000e+00, 2.00000e+00]),\n",
              " array([  1. ,  30.5,  60. ,  89.5, 119. , 148.5, 178. , 207.5, 237. ,\n",
              "        266.5, 296. ]),\n",
              " <BarContainer object of 10 artists>)"
            ]
          },
          "metadata": {},
          "execution_count": 30
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Creating the text vectorization layer"
      ],
      "metadata": {
        "id": "mAgV8vNA16GI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "output_seq_len=int(np.percentile(sen_lens,95))\n",
        "output_seq_len #no of tokens that cover 95% of the data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "72kG0i1T8bcr",
        "outputId": "469b53e4-c0d3-425b-e5b5-2eb98b52b45c"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "55"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Here we are mapping our texts from words to numbers"
      ],
      "metadata": {
        "id": "Sdo_une166QP"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_tokens=68000 #Max no of words in the text"
      ],
      "metadata": {
        "id": "mgm45sXL7HlN"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization #Importing the text vectorization "
      ],
      "metadata": {
        "id": "raFBdpqX7Qui"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_vectorization=TextVectorization(max_tokens=max_tokens,\n",
        "                                     output_sequence_length=output_seq_len,)#Max Tokens is the max number of words in Vocabulary that is common\n",
        "#OUTPUT sequence length is the max out sequence length that most of the len of statements cover"
      ],
      "metadata": {
        "id": "iaFBujYi7h_K"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_vectorization.adapt(train_sentences)"
      ],
      "metadata": {
        "id": "suDxu2waCDSa"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "ran_sen=random.choice(train_sentences)\n",
        "ran_text=text_vectorization([ran_sen]) #Testing the text vectorizer"
      ],
      "metadata": {
        "id": "R1xrz_BNCNV1"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ran_text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w-JIbSVIC1RJ",
        "outputId": "1a1214f2-943c-4cbb-c39d-7e0d1601e8d4"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 55), dtype=int64, numpy=\n",
              "array([[ 1493,     5,     2,    17,   441,     9,  1162,     5, 31091,\n",
              "         2690,     4,  9313,   307,    64,     3,   145,    67,     9,\n",
              "           92,   630,    27,    97,  2870,  2007,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0]])>"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Knowing about the vocabulary"
      ],
      "metadata": {
        "id": "6O8bFog2Dliz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "getting_vocab=text_vectorization.get_vocabulary() #The most common used vocab and the least common used vocab\n",
        "print(f'The Most Frequent words:{getting_vocab[:5]}')\n",
        "print(f'The Less Frequent words:{getting_vocab[-5:]}')\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oo5RJ0NwDqgA",
        "outputId": "8f314584-a136-4fc9-c808-18d765ba54f8"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The Most Frequent words:['', '[UNK]', 'the', 'and', 'of']\n",
            "The Less Frequent words:['aainduced', 'aaigroup', 'aachener', 'aachen', 'aaacp']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text_vectorization.get_config()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pK-S2c3pEF0q",
        "outputId": "8129c56a-c8c0-48ba-f4fd-52abb2461825"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'name': 'text_vectorization',\n",
              " 'trainable': True,\n",
              " 'dtype': 'string',\n",
              " 'batch_input_shape': (None,),\n",
              " 'max_tokens': 68000,\n",
              " 'standardize': 'lower_and_strip_punctuation',\n",
              " 'split': 'whitespace',\n",
              " 'ngrams': None,\n",
              " 'output_mode': 'int',\n",
              " 'output_sequence_length': 55,\n",
              " 'pad_to_max_tokens': False,\n",
              " 'sparse': False,\n",
              " 'ragged': False,\n",
              " 'vocabulary': None,\n",
              " 'idf_weights': None,\n",
              " 'encoding': 'utf-8',\n",
              " 'vocabulary_size': 64841}"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Creating the Embedding layer"
      ],
      "metadata": {
        "id": "QidsrnlWETy1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "embeded_layer=layers.Embedding(input_dim=len(getting_vocab),output_dim=128,mask_zero=True,name=\"Token_Embedding\")#The embedding layer after using the text vectorization"
      ],
      "metadata": {
        "id": "B-XFAdJhLE2_"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Testing the layers"
      ],
      "metadata": {
        "id": "2w6oo8zKLrtB"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "target_sen=random.choice(train_sentences) #Testing the Embedding layer on the random sequence\n",
        "target_sen_vec=text_vectorization([target_sen])\n",
        "print(f'The target sen Before Vec is {target_sen}')\n",
        "print(f'The target sen vec is {target_sen_vec}')\n",
        "embed_layer=embeded_layer(target_sen_vec)\n",
        "print(f'The embedded layer is {embed_layer}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "551JGhG_Lvoi",
        "outputId": "65aaf49d-bc4a-48ea-caf8-eac5a9205921"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The target sen Before Vec is no severe adverse events were noted in any patient during the study period .\n",
            "The target sen vec is [[ 33 289 118 124   9 991   5 262 127  52   2  17 173   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0]]\n",
            "The embedded layer is [[[ 0.03543595  0.02162861 -0.04289929 ... -0.02234229  0.0319518\n",
            "   -0.01809762]\n",
            "  [-0.01235729  0.02691669  0.01290888 ... -0.04459108  0.04192592\n",
            "    0.00844596]\n",
            "  [-0.0226521   0.01843065 -0.00660639 ...  0.00956458 -0.01418997\n",
            "    0.01963761]\n",
            "  ...\n",
            "  [-0.01120341 -0.0328212  -0.03799621 ... -0.02199611  0.02861058\n",
            "    0.02519039]\n",
            "  [-0.01120341 -0.0328212  -0.03799621 ... -0.02199611  0.02861058\n",
            "    0.02519039]\n",
            "  [-0.01120341 -0.0328212  -0.03799621 ... -0.02199611  0.02861058\n",
            "    0.02519039]]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Converting the datasets into tensorflow datasets"
      ],
      "metadata": {
        "id": "DhBH9naii1ul"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset=tf.data.Dataset.from_tensor_slices((train_sentences,train_labels_encoded))\n",
        "val_dataset=tf.data.Dataset.from_tensor_slices((val_sentences,val_labels_encoded))\n",
        "test_dataset=tf.data.Dataset.from_tensor_slices((test_sentences,test_labels_encoded))"
      ],
      "metadata": {
        "id": "oc17BF_SZgAE"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4M_Y7CbdsqNM",
        "outputId": "f22f64ac-5929-464f-f0cf-9c569eac0fa7"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<_TensorSliceDataset element_spec=(TensorSpec(shape=(), dtype=tf.string, name=None), TensorSpec(shape=(), dtype=tf.int64, name=None))>"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Take the tensorslicedataset and turn them into fetched dataset we can process the data quickly"
      ],
      "metadata": {
        "id": "9p7XXUQmaEnW"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset=train_dataset.batch(32).prefetch(tf.data.AUTOTUNE)\n",
        "val_dataset=val_dataset.batch(32).prefetch(tf.data.AUTOTUNE)\n",
        "test_dataset=test_dataset.batch(32).prefetch(tf.data.AUTOTUNE)"
      ],
      "metadata": {
        "id": "HSJbsjRqahMi"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eL5OtimfbFP3",
        "outputId": "56755839-04b9-44e4-9061-7f3af0a8fe38"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<_PrefetchDataset element_spec=(TensorSpec(shape=(None,), dtype=tf.string, name=None), TensorSpec(shape=(None,), dtype=tf.int64, name=None))>"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Model Building"
      ],
      "metadata": {
        "id": "212faWyDkBjS"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p5LKSNe3m2gx",
        "outputId": "61ccc045-2757-4da5-d3a9-19885aa9ace4"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<_PrefetchDataset element_spec=(TensorSpec(shape=(None,), dtype=tf.string, name=None), TensorSpec(shape=(None,), dtype=tf.int64, name=None))>"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_classes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JEbbRjbNm5nI",
        "outputId": "d2f524b1-0fff-41e3-a836-caa678c3e0da"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Model 1"
      ],
      "metadata": {
        "id": "6eyP35d_VeAM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#First we are buiding the ConvlD model that is used for the sequence text classification"
      ],
      "metadata": {
        "id": "9SSZEI-mjBn6"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputs=layers.Input(shape=(1,),dtype=tf.string) #input shape\n",
        "text_vectorizer=text_vectorization(inputs)\n",
        "token_embedded=embeded_layer(text_vectorizer)\n",
        "x=layers.Conv1D(64,kernel_size=5,padding='same',activation='relu')(token_embedded)#ACTIVATION relu\n",
        "x=layers.GlobalAveragePooling1D()(x)\n",
        "outputs=layers.Dense(5,activation='softmax')(x)#OUTPUT neurons 5\n",
        "model_1=tf.keras.Model(inputs,outputs)"
      ],
      "metadata": {
        "id": "HtPyhciRkGPG"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_1.compile(loss=\"sparse_categorical_crossentropy\", # if your labels are integer form (not one hot) use sparse_categorical_crossentropy\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=[\"accuracy\"])"
      ],
      "metadata": {
        "id": "VqaZ_sPKliw9"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_1.summary()#Model summary"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HZLQj-BEl-HP",
        "outputId": "6df64c51-964d-446d-8f41-1923dbca7e43"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 1)]               0         \n",
            "                                                                 \n",
            " text_vectorization (TextVec  (None, 55)               0         \n",
            " torization)                                                     \n",
            "                                                                 \n",
            " Token_Embedding (Embedding)  (None, 55, 128)          8299648   \n",
            "                                                                 \n",
            " conv1d (Conv1D)             (None, 55, 64)            41024     \n",
            "                                                                 \n",
            " global_average_pooling1d (G  (None, 64)               0         \n",
            " lobalAveragePooling1D)                                          \n",
            "                                                                 \n",
            " dense (Dense)               (None, 5)                 325       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 8,340,997\n",
            "Trainable params: 8,340,997\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Fitting the model on the train data and validation on the validation data"
      ],
      "metadata": {
        "id": "Lvk0-z5jjUiX"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_1_his=model_1.fit(train_dataset,steps_per_epoch=int(len(train_dataset)),epochs=5,validation_data=val_dataset,validation_steps=int(len(val_dataset)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_GYdG6a5mDVW",
        "outputId": "88df890d-1cce-4167-ffa3-ef2504c268c2"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "5627/5627 [==============================] - 92s 14ms/step - loss: 0.6135 - accuracy: 0.7771 - val_loss: 0.5343 - val_accuracy: 0.8107\n",
            "Epoch 2/5\n",
            "5627/5627 [==============================] - 37s 7ms/step - loss: 0.4509 - accuracy: 0.8420 - val_loss: 0.5326 - val_accuracy: 0.8110\n",
            "Epoch 3/5\n",
            "5627/5627 [==============================] - 38s 7ms/step - loss: 0.3698 - accuracy: 0.8725 - val_loss: 0.5671 - val_accuracy: 0.8059\n",
            "Epoch 4/5\n",
            "5627/5627 [==============================] - 37s 6ms/step - loss: 0.3055 - accuracy: 0.8982 - val_loss: 0.6296 - val_accuracy: 0.8007\n",
            "Epoch 5/5\n",
            "5627/5627 [==============================] - 37s 7ms/step - loss: 0.2516 - accuracy: 0.9183 - val_loss: 0.7086 - val_accuracy: 0.7934\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_1_prediction = model_1.predict(test_dataset)\n",
        "model_1_prediction#Predicting on the test data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hnf5wzKKaKdN",
        "outputId": "cb9b8cf8-d2b8-44ff-80c4-e9d1a8d00499"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "942/942 [==============================] - 2s 2ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[6.11283839e-01, 5.18634133e-02, 2.37891339e-02, 2.41970137e-01,\n",
              "        7.10934773e-02],\n",
              "       [1.56746630e-03, 6.22008520e-04, 4.02936697e-01, 6.29569229e-04,\n",
              "        5.94244242e-01],\n",
              "       [1.87035548e-05, 1.01741214e-04, 9.57616091e-01, 4.26177357e-05,\n",
              "        4.22209054e-02],\n",
              "       ...,\n",
              "       [1.18387379e-05, 5.81111293e-03, 6.07945913e-05, 2.20151378e-06,\n",
              "        9.94114101e-01],\n",
              "       [1.26648264e-03, 7.01006548e-03, 7.19299191e-04, 1.54512556e-04,\n",
              "        9.90849614e-01],\n",
              "       [4.12374677e-04, 2.44269762e-02, 4.74241413e-02, 9.24271899e-06,\n",
              "        9.27727222e-01]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_1_prediction_result= tf.argmax(model_1_prediction, axis=1)\n",
        "model_1_prediction_result #Using argmax to know the labels"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U9iHe1ZGmmNc",
        "outputId": "a213875b-0ddf-427d-d587-3aac697f1d1c"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(30135,), dtype=int64, numpy=array([0, 4, 2, ..., 4, 4, 4])>"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_1_results = calculate_results(y_true=test_labels_encoded,\n",
        "                                    y_pred=model_1_prediction_result)\n",
        "model_1_results #Calculating the accuracy ,precision,recall F1 SCORE"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1TifEdh8mxO2",
        "outputId": "708db036-7f2a-4d88-fe6a-b7698b17bb59"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 78.5100381616061,\n",
              " 'precision': 0.7811867618295214,\n",
              " 'recall': 0.7851003816160611,\n",
              " 'f1': 0.7820846709809371}"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import classification_report#Importing the libraries\n",
        "from sklearn.metrics import confusion_matrix\n"
      ],
      "metadata": {
        "id": "dKsTaBDLnZa8"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy_of_model=accuracy_score(test_labels_encoded,model_1_prediction_result)"
      ],
      "metadata": {
        "id": "6m53JsDOnikW"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy_of_model#Accuracy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C2ycB9fgn83p",
        "outputId": "7c2861f1-8b05-4cdc-f60c-cfa2f860b978"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7851003816160611"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "confusion_matrix(test_labels_encoded,model_1_prediction_result) #Confusion matrix"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pG3YOWxRoChA",
        "outputId": "fb870132-3ee6-4b8f-a2b7-02aa41218147"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[2278,  530,  286,  443,   84],\n",
              "       [ 424, 3188,  175,  101,  683],\n",
              "       [ 149,  124, 8668,   78,  878],\n",
              "       [ 782,  198,  202, 1102,   49],\n",
              "       [  57,  454,  762,   17, 8423]])"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#HyperParameter Tunning Model 1"
      ],
      "metadata": {
        "id": "4zW4J99EpZfE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#After building the conv1d model then we here added the layers to increase the accuracy"
      ],
      "metadata": {
        "id": "ai3gShTqj0kF"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputs=layers.Input(shape=(1,),dtype=tf.string)\n",
        "text_vectorizer=text_vectorization(inputs)\n",
        "token_embedded=embeded_layer(text_vectorizer)\n",
        "x=layers.Conv1D(128,kernel_size=3,padding='valid',activation='relu')(token_embedded)\n",
        "x = layers.Dropout(0.2)(x)  # Dropout layer with 20% dropout rate\n",
        "x=layers.GlobalAveragePooling1D()(x)\n",
        "# Add more layers\n",
        "x = layers.Dense(64, activation='relu')(x)\n",
        "x = layers.Dense(32, activation='relu')(x)\n",
        "x = layers.Dropout(0.5)(x)#Dropout\n",
        "outputs=layers.Dense(5,activation='softmax')(x)\n",
        "model_1_hyper=tf.keras.Model(inputs,outputs)"
      ],
      "metadata": {
        "id": "a3Qxtoslpeer"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_1_hyper.compile(loss=\"sparse_categorical_crossentropy\", \n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=[\"accuracy\"])#Compiling the model"
      ],
      "metadata": {
        "id": "yT5AE1NaqOcq"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_1_hyper.summary()#Model summary"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D4KdgItzqWO_",
        "outputId": "c9834f47-14aa-40ff-8210-8191095aef08"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_2 (InputLayer)        [(None, 1)]               0         \n",
            "                                                                 \n",
            " text_vectorization (TextVec  (None, 55)               0         \n",
            " torization)                                                     \n",
            "                                                                 \n",
            " Token_Embedding (Embedding)  (None, 55, 128)          8299648   \n",
            "                                                                 \n",
            " conv1d_1 (Conv1D)           (None, 53, 128)           49280     \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 53, 128)           0         \n",
            "                                                                 \n",
            " global_average_pooling1d_1   (None, 128)              0         \n",
            " (GlobalAveragePooling1D)                                        \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 64)                8256      \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 32)                2080      \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 32)                0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 5)                 165       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 8,359,429\n",
            "Trainable params: 8,359,429\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Fitting the model"
      ],
      "metadata": {
        "id": "FNzOwusTkFg9"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_1_his=model_1_hyper.fit(train_dataset,steps_per_epoch=int(len(train_dataset)),epochs=5,batch_size=64,validation_data=val_dataset,validation_steps=int(len(val_dataset)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jPWGKLKQqagN",
        "outputId": "18e3620e-dba2-4bd5-9e37-74a1e4099fb8"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "5627/5627 [==============================] - 82s 14ms/step - loss: 0.4012 - accuracy: 0.8688 - val_loss: 0.7433 - val_accuracy: 0.7797\n",
            "Epoch 2/5\n",
            "5627/5627 [==============================] - 42s 7ms/step - loss: 0.2926 - accuracy: 0.9094 - val_loss: 0.8807 - val_accuracy: 0.7826\n",
            "Epoch 3/5\n",
            "5627/5627 [==============================] - 40s 7ms/step - loss: 0.2512 - accuracy: 0.9232 - val_loss: 1.0642 - val_accuracy: 0.7641\n",
            "Epoch 4/5\n",
            "5627/5627 [==============================] - 39s 7ms/step - loss: 0.2201 - accuracy: 0.9322 - val_loss: 1.1230 - val_accuracy: 0.7772\n",
            "Epoch 5/5\n",
            "5627/5627 [==============================] - 40s 7ms/step - loss: 0.1951 - accuracy: 0.9401 - val_loss: 1.2672 - val_accuracy: 0.7751\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_1_hyper_prediction = model_1_hyper.predict(test_dataset)\n",
        "model_1_hyper_prediction#Predicting on the test data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZEl5G0zDqngN",
        "outputId": "28507f6e-242d-42aa-c9f7-46ff196cd6a3"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "942/942 [==============================] - 2s 2ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[7.93476880e-01, 4.92351018e-02, 2.36958470e-02, 1.30428702e-01,\n",
              "        3.16343037e-03],\n",
              "       [9.71172296e-04, 1.47777284e-02, 1.63694154e-02, 1.65561170e-04,\n",
              "        9.67716038e-01],\n",
              "       [6.06699141e-05, 4.20727774e-05, 9.74270344e-01, 3.69199988e-05,\n",
              "        2.55898759e-02],\n",
              "       ...,\n",
              "       [2.63479933e-06, 1.09288783e-03, 8.13926599e-05, 1.59337716e-07,\n",
              "        9.98822868e-01],\n",
              "       [1.13505324e-04, 6.59903511e-03, 1.58946693e-03, 1.42879189e-05,\n",
              "        9.91683722e-01],\n",
              "       [5.47491936e-07, 6.18598051e-06, 2.05876204e-04, 6.06245956e-11,\n",
              "        9.99787390e-01]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_1_hyper_prediction_result= tf.argmax(model_1_hyper_prediction, axis=1)\n",
        "model_1_hyper_prediction_result#Predicting on the test data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rX2zHTZCqm-1",
        "outputId": "9b341a9f-ab58-4ad1-81a5-96ab9da93ed3"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(30135,), dtype=int64, numpy=array([0, 4, 2, ..., 4, 4, 4])>"
            ]
          },
          "metadata": {},
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_1_hyper_results = calculate_results(y_true=test_labels_encoded,\n",
        "                                    y_pred=model_1_hyper_prediction_result)\n",
        "model_1_hyper_results #Calculating the accuracy ,precision,recall F1 SCORE"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kmUNw6SgtEL3",
        "outputId": "c6bec98e-41f4-4d1a-a693-042a2860e0a0"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 76.67828106852497,\n",
              " 'precision': 0.7645430817897965,\n",
              " 'recall': 0.7667828106852497,\n",
              " 'f1': 0.7633560388387476}"
            ]
          },
          "metadata": {},
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Model2"
      ],
      "metadata": {
        "id": "q80zyHhKVhnt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#RNN MODEL This is the second model Recurrent neural network"
      ],
      "metadata": {
        "id": "lO88q5IZkSwZ"
      },
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputs=layers.Input(shape=(1,),dtype=tf.string)\n",
        "text_vectorizer=text_vectorization(inputs)#Tokenization\n",
        "token_embedded=embeded_layer(text_vectorizer) #Embedding\n",
        "x=layers.SimpleRNN(128,activation='relu')(token_embedded)\n",
        "x=layers.Dense(64,activation='relu')(x) #Adding layers\n",
        "#x=layers.GlobalAveragePooling1D()(x)\n",
        "outputs=layers.Dense(5,activation='softmax')(x)\n",
        "model_2=tf.keras.Model(inputs,outputs) \n",
        "model_2.compile(loss=\"sparse_categorical_crossentropy\", # if your labels are integer form (not one hot) use sparse_categorical_crossentropy\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=[\"accuracy\"])"
      ],
      "metadata": {
        "id": "RBGTigFpu1O7"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_2.summary() #model summary"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8na5erb_yxOi",
        "outputId": "b4711f49-f984-4b03-d1c6-d77e199e2c70"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_3 (InputLayer)        [(None, 1)]               0         \n",
            "                                                                 \n",
            " text_vectorization (TextVec  (None, 55)               0         \n",
            " torization)                                                     \n",
            "                                                                 \n",
            " Token_Embedding (Embedding)  (None, 55, 128)          8299648   \n",
            "                                                                 \n",
            " simple_rnn (SimpleRNN)      (None, 128)               32896     \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 64)                8256      \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 5)                 325       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 8,341,125\n",
            "Trainable params: 8,341,125\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Fitting the RNN model on the train data and validating on the test data"
      ],
      "metadata": {
        "id": "93Xd8SuSkjjL"
      },
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_2_his=model_2.fit(train_dataset,steps_per_epoch=int(len(train_dataset)),epochs=5,validation_data=val_dataset,validation_steps=int(len(val_dataset)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Kpfjg82y4nr",
        "outputId": "aa5e6f36-7f72-459a-a111-3070b9b7c9c6"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "5627/5627 [==============================] - 554s 98ms/step - loss: 0.3937 - accuracy: 0.8640 - val_loss: 0.7435 - val_accuracy: 0.7761\n",
            "Epoch 2/5\n",
            "5627/5627 [==============================] - 533s 95ms/step - loss: 0.2902 - accuracy: 0.9048 - val_loss: 0.7780 - val_accuracy: 0.7689\n",
            "Epoch 3/5\n",
            "5627/5627 [==============================] - 519s 92ms/step - loss: 0.2538 - accuracy: 0.9176 - val_loss: 0.8555 - val_accuracy: 0.7681\n",
            "Epoch 4/5\n",
            "5627/5627 [==============================] - 512s 91ms/step - loss: 0.2249 - accuracy: 0.9275 - val_loss: 0.8708 - val_accuracy: 0.7730\n",
            "Epoch 5/5\n",
            "5627/5627 [==============================] - 512s 91ms/step - loss: 0.2074 - accuracy: 0.9331 - val_loss: 0.9372 - val_accuracy: 0.7721\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_2_prediction = model_2.predict(test_dataset)\n",
        "model_2_prediction"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fhvzHTSSzWLX",
        "outputId": "4671617a-a1e6-4d90-953b-632fe80604a2"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "942/942 [==============================] - 10s 10ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[9.4921190e-01, 1.6282063e-03, 1.6884712e-04, 4.8324201e-02,\n",
              "        6.6679815e-04],\n",
              "       [2.2174215e-02, 6.0874461e-03, 1.4519370e-01, 1.3068288e-03,\n",
              "        8.2523775e-01],\n",
              "       [2.1616679e-03, 4.3918935e-04, 9.5868063e-01, 3.6571061e-03,\n",
              "        3.5061385e-02],\n",
              "       ...,\n",
              "       [8.4394564e-08, 7.8817997e-05, 9.9593235e-06, 2.2695421e-09,\n",
              "        9.9991107e-01],\n",
              "       [5.9942325e-04, 9.2750452e-03, 3.9409050e-03, 1.1745716e-04,\n",
              "        9.8606724e-01],\n",
              "       [8.0858573e-04, 4.3307892e-03, 7.5775608e-02, 2.9186375e-04,\n",
              "        9.1879314e-01]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_2_prediction_result= tf.argmax(model_2_prediction, axis=1)\n",
        "model_2_prediction_result#Predicting on the test data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Iiwa4XHczeFY",
        "outputId": "056eaa61-db04-4087-ade5-bddb0856d1eb"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(30135,), dtype=int64, numpy=array([0, 4, 2, ..., 4, 4, 4])>"
            ]
          },
          "metadata": {},
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#evaluating results Precision recall and F1 score"
      ],
      "metadata": {
        "id": "tUDIOZoxkuhh"
      },
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_2_results = calculate_results(y_true=test_labels_encoded,\n",
        "                                    y_pred=model_2_prediction_result)\n",
        "model_2_results #Results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6v-PsO9-zqkT",
        "outputId": "94826794-3550-4ab1-aeac-deb1e9358910"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 76.80438028870084,\n",
              " 'precision': 0.7702662020124156,\n",
              " 'recall': 0.7680438028870085,\n",
              " 'f1': 0.7657185382314029}"
            ]
          },
          "metadata": {},
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Model 3"
      ],
      "metadata": {
        "id": "eDd8vNzF0B1x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#After Conv1D,RNN and the third model we build is LSTM Long short term memory"
      ],
      "metadata": {
        "id": "3IT_Iw3uk1_I"
      },
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputs=layers.Input(shape=(1,),dtype=tf.string)\n",
        "text_vectorizer=text_vectorization(inputs)\n",
        "token_embedded=embeded_layer(text_vectorizer)\n",
        "x=layers.LSTM(64)(token_embedded)\n",
        "#x=layers.GlobalAveragePooling1D()(x)\n",
        "outputs=layers.Dense(5,activation='softmax')(x)\n",
        "model_3=tf.keras.Model(inputs,outputs) "
      ],
      "metadata": {
        "id": "hF0E5fH5sfij"
      },
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_3.compile(loss=\"sparse_categorical_crossentropy\", # if your labels are integer form (not one hot) use sparse_categorical_crossentropy\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=[\"accuracy\"])"
      ],
      "metadata": {
        "id": "mbtBCAPjcdOD"
      },
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_3.summary() #LSTM model summary"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C2h4awTtcd99",
        "outputId": "f1d6a0dc-1e25-492d-9a57-3e79934b4257"
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_4 (InputLayer)        [(None, 1)]               0         \n",
            "                                                                 \n",
            " text_vectorization (TextVec  (None, 55)               0         \n",
            " torization)                                                     \n",
            "                                                                 \n",
            " Token_Embedding (Embedding)  (None, 55, 128)          8299648   \n",
            "                                                                 \n",
            " lstm (LSTM)                 (None, 64)                49408     \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 5)                 325       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 8,349,381\n",
            "Trainable params: 8,349,381\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Fitting the model on train data and validating on the validation data"
      ],
      "metadata": {
        "id": "bt19OV6glJZ5"
      },
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_3_his=model_3.fit(train_dataset,steps_per_epoch=int(len(train_dataset)),epochs=5,validation_data=val_dataset,validation_steps=int(len(val_dataset)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vr3dzYEtckMI",
        "outputId": "a8b554e3-c6d1-4242-9564-d003a06271fd"
      },
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "5627/5627 [==============================] - 106s 18ms/step - loss: 0.2292 - accuracy: 0.9226 - val_loss: 0.8556 - val_accuracy: 0.7724\n",
            "Epoch 2/5\n",
            "5627/5627 [==============================] - 71s 13ms/step - loss: 0.1501 - accuracy: 0.9504 - val_loss: 1.0027 - val_accuracy: 0.7686\n",
            "Epoch 3/5\n",
            "5627/5627 [==============================] - 71s 13ms/step - loss: 0.1193 - accuracy: 0.9608 - val_loss: 1.0863 - val_accuracy: 0.7685\n",
            "Epoch 4/5\n",
            "5627/5627 [==============================] - 68s 12ms/step - loss: 0.0982 - accuracy: 0.9679 - val_loss: 1.2135 - val_accuracy: 0.7713\n",
            "Epoch 5/5\n",
            "5627/5627 [==============================] - 71s 13ms/step - loss: 0.0821 - accuracy: 0.9735 - val_loss: 1.2565 - val_accuracy: 0.7660\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_3_prediction = model_3.predict(test_dataset)\n",
        "model_3_prediction"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CobRchmqzxA5",
        "outputId": "9a6c8f9d-53a0-42b9-815e-f635cd52ed59"
      },
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "942/942 [==============================] - 5s 4ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[8.54541838e-01, 2.37056855e-02, 1.75192673e-02, 1.02637760e-01,\n",
              "        1.59550249e-03],\n",
              "       [1.20909866e-02, 5.13407867e-03, 8.26166928e-01, 3.37004079e-03,\n",
              "        1.53237998e-01],\n",
              "       [1.10523775e-04, 4.65982557e-05, 9.93951201e-01, 5.54612488e-04,\n",
              "        5.33709070e-03],\n",
              "       ...,\n",
              "       [1.50553278e-05, 2.33687740e-03, 2.17330919e-04, 1.16387382e-05,\n",
              "        9.97419119e-01],\n",
              "       [1.54479014e-04, 7.88801908e-02, 9.36791941e-04, 1.57257455e-04,\n",
              "        9.19871271e-01],\n",
              "       [4.67985265e-05, 2.09667650e-03, 9.38544399e-05, 6.95509789e-06,\n",
              "        9.97755706e-01]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_3_prediction_result= tf.argmax(model_3_prediction, axis=1)\n",
        "model_3_prediction_result #Predicting on the test data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "93BXE2shztYs",
        "outputId": "06fbab16-4b7e-476d-c2fb-793b246ae07a"
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(30135,), dtype=int64, numpy=array([0, 2, 2, ..., 4, 4, 4])>"
            ]
          },
          "metadata": {},
          "execution_count": 91
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_3_results = calculate_results(y_true=test_labels_encoded,\n",
        "                                    y_pred=model_3_prediction_result)\n",
        "model_3_results #Evaluating the results"
      ],
      "metadata": {
        "id": "xMB4Aq0_7gUX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0f9ca433-b508-47bb-fb78-a54558c58655"
      },
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 75.59316409490626,\n",
              " 'precision': 0.7552776487736308,\n",
              " 'recall': 0.7559316409490625,\n",
              " 'f1': 0.7550687823789778}"
            ]
          },
          "metadata": {},
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Model4"
      ],
      "metadata": {
        "id": "s4pB2Fes_kMd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Taking the example abstract and testing the model "
      ],
      "metadata": {
        "id": "DUehwmH6_mhN"
      },
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "example='This RCT examined the efficacy of a manualized social intervention for children with HFASDs. Participants were randomly assigned to treatment or wait-list conditions. Treatment included instruction and therapeutic activities targeting social skills, face-emotion recognition, interest expansion, and interpretation of non-literal language. A response-cost program was applied to reduce problem behaviors and foster skills acquisition. Significant treatment effects were found for five of seven primary outcome measures (parent ratings and direct child measures). Secondary measures based on staff ratings (treatment group only) corroborated gains reported by parents. High levels of parent, child and staff satisfaction were reported, along with high levels of treatment fidelity. Standardized effect size estimates were primarily in the medium and large ranges and favored the treatment group.'\n",
        "\n"
      ],
      "metadata": {
        "id": "yYMGnsGVI8xm"
      },
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "example.split('.')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fH3cgAOkJF_L",
        "outputId": "7c3ea0dd-32d5-4d55-da93-04f304c7204c"
      },
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['This RCT examined the efficacy of a manualized social intervention for children with HFASDs',\n",
              " ' Participants were randomly assigned to treatment or wait-list conditions',\n",
              " ' Treatment included instruction and therapeutic activities targeting social skills, face-emotion recognition, interest expansion, and interpretation of non-literal language',\n",
              " ' A response-cost program was applied to reduce problem behaviors and foster skills acquisition',\n",
              " ' Significant treatment effects were found for five of seven primary outcome measures (parent ratings and direct child measures)',\n",
              " ' Secondary measures based on staff ratings (treatment group only) corroborated gains reported by parents',\n",
              " ' High levels of parent, child and staff satisfaction were reported, along with high levels of treatment fidelity',\n",
              " ' Standardized effect size estimates were primarily in the medium and large ranges and favored the treatment group',\n",
              " '']"
            ]
          },
          "metadata": {},
          "execution_count": 95
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_0.predict(example.split('.'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xNBYI1iuKC92",
        "outputId": "307eb10b-f62d-4cf4-9534-19ad0935ef78"
      },
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 2, 4, 2, 4, 2, 4, 2, 2])"
            ]
          },
          "metadata": {},
          "execution_count": 96
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_1.predict(example.split('.'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CD86MHM1JMXP",
        "outputId": "5bc44bf8-1adc-4400-b925-d3449f1099ad"
      },
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 138ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1.11115359e-01, 1.80860639e-01, 5.25506496e-01, 1.30784530e-02,\n",
              "        1.69439048e-01],\n",
              "       [2.99964217e-03, 2.99824496e-05, 9.74276006e-01, 4.26984718e-03,\n",
              "        1.84245817e-02],\n",
              "       [4.33151834e-02, 4.31704335e-02, 8.99316728e-01, 8.46420880e-03,\n",
              "        5.73344668e-03],\n",
              "       [4.36682403e-01, 6.61152229e-02, 1.44169107e-01, 4.00158726e-02,\n",
              "        3.13017368e-01],\n",
              "       [8.13790073e-04, 3.24694416e-03, 4.11772076e-03, 5.43567912e-05,\n",
              "        9.91767228e-01],\n",
              "       [8.48262705e-09, 2.36619849e-06, 1.81692883e-09, 2.73522677e-10,\n",
              "        9.99997616e-01],\n",
              "       [2.82475092e-02, 2.44163312e-02, 2.52420336e-01, 2.46596728e-02,\n",
              "        6.70256138e-01],\n",
              "       [1.07853196e-03, 3.81992105e-03, 4.04619202e-02, 3.97582568e-04,\n",
              "        9.54241991e-01],\n",
              "       [1.55220374e-01, 1.03234164e-01, 3.48994881e-01, 9.38641056e-02,\n",
              "        2.98686445e-01]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 97
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf.argmax(model_1.predict(example.split('.')), axis=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MSa2xUbYJ1GD",
        "outputId": "2e9d3cf3-554f-41f0-9a8f-032f91f714b6"
      },
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 32ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(9,), dtype=int64, numpy=array([2, 2, 2, 0, 4, 4, 4, 4, 2])>"
            ]
          },
          "metadata": {},
          "execution_count": 98
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "label_encoder.classes_"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VB9B1pjsJVNJ",
        "outputId": "cf32213a-780a-443c-eee2-4e840175cb26"
      },
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['BACKGROUND', 'CONCLUSIONS', 'METHODS', 'OBJECTIVE', 'RESULTS'],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 99
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "potp3x3nW-SO"
      },
      "execution_count": 99,
      "outputs": []
    }
  ]
}